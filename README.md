# Auralis 
### Real-time Generative Ambient Music in Python  

Auralis is an open-source **generative ambient music engine** built with **Python 3**, **FastAPI**, and **PyTorch**.  
It composes and streams evolving, atmospheric soundscapes â€” complete with synth pads, minimalist percussion, and slowly shifting melodies â€” **in real time** to connected web clients.

***

## ğŸ§ Overview

Auralis generates continuous ambient sound that never repeats, blending algorithmic composition, differentiable synthesis, and real-time streaming.

- **Generative Composition:** Markov chord progressions + constraint-based or transformer melodies.  
- **Real-Time Rendering:** GPU-accelerated **torchsynth** synthesis for pads, leads, and textures.  
- **Adaptive Streaming:** FastAPI WebSocket server sends audio at 100â€¯ms intervals with low-latency buffering.  
- **Web Playback:** Web Audio API client handles playback, jitter correction, and user controls.

***

## ğŸ§  System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Composition  â”‚  --->  â”‚  Synthesis Core  â”‚  --->  â”‚ Ring Buffer   â”‚
â”‚  (Markov &   â”‚        â”‚  (torchsynth)   â”‚        â”‚  + Encoder    â”‚
â”‚  Constraints)â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
                                                           â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  FastAPI Server  â”‚
                                               â”‚ (WebSocket out)  â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚  base64 PCM chunks
                                                      â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚ Web Client (Web Audio API)     â”‚
                                      â”‚ Adaptive buffering + playback  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

***

## âœ¨ Features

| Layer | Description |
|-------|--------------|
| ğŸ¼ **Composition** | Chord progressions driven by Markov chains and constraint-based melody generation |
| ğŸ›ï¸ **Synthesis** | Real-time GPU synthesizer using *torchsynth* â€” multiple oscillators, filters, and ADSR envelopes |
| ğŸ”„ **Streaming** | 100â€¯ms audio chunks streamed over WebSockets via FastAPI |
| ğŸ§  **Adaptive Buffering** | Client adjusts playback rate to maintain seamless streaming |
| ğŸ’» **Live Controls** | Change key, BPM, or mood intensity from the browser |
| ğŸ“Š **Metrics** | Real-time performance monitoring via REST `/api/metrics` |

***

## ğŸ—ï¸ Installation

### Requirements
- Python 3.10+  
- macOS (M1/M2/M4) or Linux with CUDA/Metal support  
- Node.js 18+ (for client build)

```bash
# Clone repo
git clone https://github.com/yourusername/auralis.git
cd auralis

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# (Optional) enable Apple GPU acceleration
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Run the development server
uvicorn server.main:app --reload

# Open client
open client/index.html
```

***

## ğŸ§© Project Structure

```
auralis/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py                # FastAPI entrypoint
â”‚   â”œâ”€â”€ synthesis_engine.py    # torchsynth synthesis core
â”‚   â”œâ”€â”€ ring_buffer.py         # Audio buffering
â”‚   â””â”€â”€ streaming_server.py    # WebSocket streaming logic
â”‚
â”œâ”€â”€ composition/
â”‚   â”œâ”€â”€ chord_generator.py     # Markov chord engine
â”‚   â”œâ”€â”€ melody_generator.py    # Constraint/transformer melody
â”‚   â””â”€â”€ percussion_generator.py# Minimal ambient percussion
â”‚
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ audio_client.js        # Web Audio playback
â”‚   â””â”€â”€ index.html             # Basic control UI
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ system_architecture.md
â”‚   â”œâ”€â”€ implementation_strategies.md
â”‚   â””â”€â”€ implementation_plan.md
â”‚
â””â”€â”€ README.md
```

***

## ğŸŒˆ Usage

### Run the streaming engine
```bash
uvicorn server.main:app --host 0.0.0.0 --port 8000
```

### Open the client in your browser
```bash
open client/index.html
```

Youâ€™ll hear Auralis generate evolving ambient music in real time.  
Use the on-screen controls to modify **key**, **BPM**, and **intensity**.

***

## ğŸ§ª Development Phases

| Phase | Focus |
|-------|--------|
| **1** | MVP â€“ Markov chords, constraint melodies, basic synthesis |
| **2** | Real-time control, percussion, adaptive buffering |
| **3** | GPU optimization, effects (reverb, delay), monitoring |
| **4** | Production readiness, error handling, deployment |

See [`docs/implementation_plan.md`](docs/implementation_plan.md) for full details.

---

## ğŸ› ï¸ Tech Stack

- **Python:** FastAPI, asyncio, PyTorch, torchsynth, numpy  
- **Frontend:** Web Audio API, JavaScript, HTML5  
- **Audio:** 44.1â€¯kHz, 16-bit PCM chunks streamed every 100â€¯ms  
- **Optional:** Opus compression, DistilGPTâ€‘2 melody transformer  

***

## ğŸ“Š Monitoring

Every 10â€¯seconds:
- Logs buffer depth, synthesis latency, active clients  
- Reports metrics via `/api/metrics` REST endpoint  
- Future: Prometheus adapter and GPU profiling dashboard  

***

## ğŸ¨ Roadmap

- [ ] Transformer-conditioned lead melodies  
- [ ] Dynamic percussion textures  
- [ ] Cloud deployment with WebRTC streaming  
- [ ] User presets + MIDI export  
- [ ] Offline render to full-length ambient pieces  

***

## ğŸ§‘â€ğŸ’» Contributors

- **You!** Pull requests welcome â€” whether itâ€™s improving synthesis modules, adding new compositional algorithms, or refining the client experience.

***

## ğŸ“œ License

MIT License - Copyright 2025  
Developed by Andrew MArconi
